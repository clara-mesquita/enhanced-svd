{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9cbecfc",
   "metadata": {},
   "source": [
    "### CESNET-TimeSeries24 → minimal throughput datasets\n",
    "Creates per-entity CSVs with only:\n",
    "- time\n",
    "- throughput_bytes (equal to n_bytes in the interval)\n",
    "# \n",
    "Optional: bytes_per_second\n",
    "#\n",
    "Works for:\n",
    "- institutions/\n",
    "- institution_subnets/\n",
    "- ip_addresses_sample/\n",
    "- ip_addresses_full/ (nested folder structure handled)\n",
    "#\n",
    "Output mirrors the input structure by default (can be changed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b727892f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Imports & Config\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from typing import Dict, Iterable, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "DATA_ROOT = Path(\"../CESNET-TimeSeries24\") \n",
    "OUTPUT_ROOT = Path(\"cesnet-institutions-throughput\") \n",
    "\n",
    "SCOPES = [\n",
    "    \"institutions\",\n",
    "    # \"institution_subnets\",\n",
    "    # \"ip_addresses_sample\",\n",
    "    # \"ip_addresses_full\", \n",
    "]\n",
    "\n",
    "AGG_LEVELS = {\n",
    "    \"agg_10_minutes\": 600,    # seconds in window\n",
    "    \"agg_1_hour\": 3600,\n",
    "    \"agg_1_day\": 86400,\n",
    "}\n",
    "\n",
    "CSV_COMPRESSION = \"infer\"       # e.g. \"gzip\" to compress (adds .gz)\n",
    "\n",
    "pd.options.mode.copy_on_write = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38595ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['agg_10_minutes', 'agg_1_hour', 'agg_1_day'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% Helpers to load the official time maps once per aggregation\n",
    "def load_time_map(data_root: Path) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Load times_* CSVs into {agg_level: DataFrame[id_time, time]} dict.\n",
    "    Ensures 'time' is pandas datetime.\n",
    "    \"\"\"\n",
    "    times_dir = data_root / \"times\"\n",
    "    time_map = {}\n",
    "\n",
    "    fname_by_agg = {\n",
    "        \"agg_10_minutes\": \"times_10_minutes.csv\",\n",
    "        \"agg_1_hour\": \"times_1_hour.csv\",\n",
    "        \"agg_1_day\": \"times_1_day.csv\",\n",
    "    }\n",
    "\n",
    "    for agg, fname in fname_by_agg.items():\n",
    "        fp = times_dir / fname\n",
    "        if not fp.exists():\n",
    "            raise FileNotFoundError(f\"Missing time file: {fp}\")\n",
    "        df = pd.read_csv(fp)\n",
    "        # Expect columns: id_time, time (string)\n",
    "        if \"id_time\" not in df or \"time\" not in df:\n",
    "            raise ValueError(f\"{fp} must contain 'id_time' and 'time' columns.\")\n",
    "        df = df[[\"id_time\", \"time\"]].copy()\n",
    "        df[\"time\"] = pd.to_datetime(df[\"time\"], utc=True).dt.tz_localize(None)# keep tz-aware; drop .tz_convert if needed\n",
    "        time_map[agg] = df\n",
    "    return time_map\n",
    "\n",
    "time_map = load_time_map(DATA_ROOT)\n",
    "time_map.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9966331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Utility: discover all per-entity CSVs for a given scope+agg level\n",
    "def iter_entity_files(scope: str, agg_level: str) -> Iterable[Tuple[Path, Path]]:\n",
    "    \"\"\"\n",
    "    Yield (input_csv_path, relative_output_path) for the given scope and agg_level.\n",
    "\n",
    "    For 'ip_addresses_full', input files live in nested folders:\n",
    "        ip_addresses_full/agg_10_minutes/<folder>/<id_ip>.csv\n",
    "    For other scopes:\n",
    "        <scope>/<agg_level>/<id>.csv\n",
    "    \"\"\"\n",
    "    scope_dir = DATA_ROOT / scope / agg_level\n",
    "    if not scope_dir.exists():\n",
    "        return  # empty iterator\n",
    "\n",
    "    if scope == \"ip_addresses_full\":\n",
    "        # nested structure two levels deep: */*.csv\n",
    "        pattern = str(scope_dir / \"*\" / \"*.csv\")\n",
    "        for inp in glob.glob(pattern):\n",
    "            inp = Path(inp)\n",
    "            # preserve nested structure under output\n",
    "            rel = inp.relative_to(DATA_ROOT)\n",
    "            yield inp, rel\n",
    "    else:\n",
    "        # flat csvs directly in agg folder\n",
    "        pattern = str(scope_dir / \"*.csv\")\n",
    "        for inp in glob.glob(pattern):\n",
    "            inp = Path(inp)\n",
    "            rel = inp.relative_to(DATA_ROOT)\n",
    "            yield inp, rel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f756d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Core processor\n",
    "def process_one_file(inp_csv: Path, rel_out_path: Path, agg_level: str, out_root: Path):\n",
    "    \"\"\"\n",
    "    Read one CESNET CSV, join time, keep only [time, throughput_bytes, (bytes_per_second?)].\n",
    "    Write to OUTPUT_ROOT mirrored path.\n",
    "    \"\"\"\n",
    "    # Read minimal columns\n",
    "    # Schemas differ slightly between native (10m) and re-aggregated (1h/1d),\n",
    "    # but they always have: id_time, n_bytes\n",
    "    usecols = [\"id_time\", \"n_bytes\"]\n",
    "    df = pd.read_csv(inp_csv, usecols=usecols)\n",
    "\n",
    "    # Join with time map\n",
    "    tm = time_map[agg_level]\n",
    "    out = df.merge(tm, on=\"id_time\", how=\"left\", validate=\"many_to_one\")\n",
    "\n",
    "    # Sanity checks\n",
    "    if out[\"time\"].isna().any():\n",
    "        missing = out[\"time\"].isna().sum()\n",
    "        raise ValueError(f\"{inp_csv}: {missing} rows had id_time not found in {agg_level} time map.\")\n",
    "\n",
    "    seconds = AGG_LEVELS[agg_level]\n",
    "    \n",
    "    # Build throughput (bps) dataset\n",
    "    out_df = pd.DataFrame({\n",
    "        \"time\": pd.to_datetime(out[\"time\"], utc=False),\n",
    "        \"throughput_bps\": out[\"n_bytes\"].astype(\"int64\") / float(seconds)\n",
    "    })        \n",
    "\n",
    "    # Prepare output path (mirror tree, but under OUTPUT_ROOT and rename file)\n",
    "    # Change file name to emphasize this is a minimal throughput dataset\n",
    "    # e.g., replace \"x.csv\" with \"x.throughput.csv\"\n",
    "    os.makedirs(out_root, exist_ok=True)\n",
    "    out_path = out_root / rel_out_path\n",
    "    out_path = out_path.with_name(out_path.stem + \".throughput.csv\")\n",
    "\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    out_df.to_csv(out_path, index=False, compression=CSV_COMPRESSION)\n",
    "\n",
    "    return out_df.shape[0], out_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b2719f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[start] institutions/agg_10_minutes\n",
      "[done ] institutions/agg_10_minutes → files: 283 rows: 10,446,225\n",
      "[start] institutions/agg_1_hour\n",
      "[done ] institutions/agg_1_hour → files: 283 rows: 1,880,182\n",
      "[start] institutions/agg_1_day\n",
      "[done ] institutions/agg_1_day → files: 283 rows: 78,667\n",
      "\n",
      "All done in 24.3s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scope</th>\n",
       "      <th>agg_level</th>\n",
       "      <th>n_files</th>\n",
       "      <th>n_rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>institutions</td>\n",
       "      <td>agg_10_minutes</td>\n",
       "      <td>283</td>\n",
       "      <td>10446225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>institutions</td>\n",
       "      <td>agg_1_hour</td>\n",
       "      <td>283</td>\n",
       "      <td>1880182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>institutions</td>\n",
       "      <td>agg_1_day</td>\n",
       "      <td>283</td>\n",
       "      <td>78667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          scope       agg_level  n_files    n_rows\n",
       "0  institutions  agg_10_minutes      283  10446225\n",
       "1  institutions      agg_1_hour      283   1880182\n",
       "2  institutions       agg_1_day      283     78667"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% Driver: run for all SCOPES and AGG_LEVELS\n",
    "from time import perf_counter\n",
    "\n",
    "def run_all(\n",
    "    scopes=SCOPES,\n",
    "    agg_levels=AGG_LEVELS.keys(),\n",
    "    out_root: Path = OUTPUT_ROOT,\n",
    "):\n",
    "    totals = []\n",
    "    t0 = perf_counter()\n",
    "    for scope in scopes:\n",
    "        for agg in agg_levels:\n",
    "            scope_dir = DATA_ROOT / scope / agg\n",
    "            if not scope_dir.exists():\n",
    "                print(f\"[skip] {scope}/{agg}: not found.\")\n",
    "                continue\n",
    "\n",
    "            print(f\"[start] {scope}/{agg}\")\n",
    "            n_files = 0\n",
    "            n_rows = 0\n",
    "            for inp_csv, rel in iter_entity_files(scope, agg):\n",
    "                try:\n",
    "                    rows, outp = process_one_file(\n",
    "                        inp_csv=inp_csv,\n",
    "                        rel_out_path=rel,\n",
    "                        agg_level=agg,\n",
    "                        out_root=out_root,\n",
    "                    )\n",
    "                    n_files += 1\n",
    "                    n_rows += rows\n",
    "                except Exception as e:\n",
    "                    # Avoid crashing on one bad file; report and continue\n",
    "                    print(f\"  [error] {inp_csv}: {e}\", file=sys.stderr)\n",
    "            print(f\"[done ] {scope}/{agg} → files: {n_files:,} rows: {n_rows:,}\")\n",
    "            totals.append((scope, agg, n_files, n_rows))\n",
    "\n",
    "    t1 = perf_counter()\n",
    "    print(f\"\\nAll done in {t1 - t0:.1f}s\")\n",
    "    return pd.DataFrame(totals, columns=[\"scope\", \"agg_level\", \"n_files\", \"n_rows\"])\n",
    "\n",
    "summary = run_all()\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2223d98c",
   "metadata": {},
   "source": [
    "### What you get\n",
    "- Output folder structure mirrors input, e.g.:\n",
    "#\n",
    "    OUTPUT_ROOT/\n",
    "      institutions/\n",
    "          agg_10_minutes/1234.throughput.csv\n",
    "          agg_1_hour/1234.throughput.csv\n",
    "          agg_1_day/1234.throughput.csv\n",
    "      institution_subnets/...\n",
    "      ip_addresses_sample/...\n",
    "      ip_addresses_full/<folder>/<id_ip>.throughput.csv\n",
    "#\n",
    "Each file has:\n",
    "  time, throughput_bps\n",
    "#\n",
    "- throughput_bps == n_bytes per second for the given aggregation window (10m, 1h, 1d), \"bytes per time\" as a *rate*\n",
    "- Timestamps are UTC; drop .tz_convert if you want naive timestamps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3df18283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cesnet-institutions-throughput/institutions/agg_10_minutes/5.throughput.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>throughput_bps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-10-09 00:03:49</td>\n",
       "      <td>1663.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-10-09 00:13:49</td>\n",
       "      <td>2753.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-10-09 00:23:49</td>\n",
       "      <td>9289.098333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-10-09 00:33:49</td>\n",
       "      <td>2934.731667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-10-09 00:43:49</td>\n",
       "      <td>3351.446667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time  throughput_bps\n",
       "0  2023-10-09 00:03:49     1663.130000\n",
       "1  2023-10-09 00:13:49     2753.990000\n",
       "2  2023-10-09 00:23:49     9289.098333\n",
       "3  2023-10-09 00:33:49     2934.731667\n",
       "4  2023-10-09 00:43:49     3351.446667"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cesnet-institutions-throughput/institutions/agg_1_day/5.throughput.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>throughput_bps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-10-09</td>\n",
       "      <td>203520.392338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-10-10</td>\n",
       "      <td>212837.188287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-10-11</td>\n",
       "      <td>186500.295255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-10-12</td>\n",
       "      <td>236941.003715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-10-13</td>\n",
       "      <td>191074.822303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         time  throughput_bps\n",
       "0  2023-10-09   203520.392338\n",
       "1  2023-10-10   212837.188287\n",
       "2  2023-10-11   186500.295255\n",
       "3  2023-10-12   236941.003715\n",
       "4  2023-10-13   191074.822303"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cesnet-institutions-throughput/institutions/agg_1_hour/5.throughput.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>throughput_bps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-10-09 00:00:00</td>\n",
       "      <td>3560.270833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-10-09 01:00:00</td>\n",
       "      <td>4951.698056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-10-09 02:00:00</td>\n",
       "      <td>37455.998333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-10-09 03:00:00</td>\n",
       "      <td>422775.234444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-10-09 04:00:00</td>\n",
       "      <td>963996.973611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time  throughput_bps\n",
       "0  2023-10-09 00:00:00     3560.270833\n",
       "1  2023-10-09 01:00:00     4951.698056\n",
       "2  2023-10-09 02:00:00    37455.998333\n",
       "3  2023-10-09 03:00:00   422775.234444\n",
       "4  2023-10-09 04:00:00   963996.973611"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %% Quick verification (adjust paths to a recent output you have)\n",
    "examples = list(OUTPUT_ROOT.rglob(\"5.throughput.csv\"))[:3]\n",
    "for p in examples:\n",
    "    print(p)\n",
    "    display(pd.read_csv(p, nrows=5))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
